{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSZHoUUrEM5OIezOrdMTMo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KavindaRajapaksha/DeepLearning/blob/main/DropoutRegulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqecZPJBSpE_",
        "outputId": "8d5b8cd0-60bb-4340-f1ca-3b8baf56f1fb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (from opendatasets) (1.6.17)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from opendatasets) (8.1.8)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.32.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.3.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.11/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle->opendatasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle->opendatasets) (3.10)\n",
            "Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zaXMDhIERioe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import opendatasets as od"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "od.download('https://www.kaggle.com/datasets/mahmudulhaqueshawon/sonar-data')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXeXQmIPSgLm",
        "outputId": "219e7e0b-66aa-4869-8659-7a1a43f89144"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: kavindasrajapaksha\n",
            "Your Kaggle Key: ··········\n",
            "Dataset URL: https://www.kaggle.com/datasets/mahmudulhaqueshawon/sonar-data\n",
            "Downloading sonar-data.zip to ./sonar-data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.1k/29.1k [00:00<00:00, 31.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/sonar-data/sonar data.csv',header=None)\n",
        "data=data.values"
      ],
      "metadata": {
        "id": "Cn5o9eeqS-Jf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfUpgUb1TThv",
        "outputId": "0d53d2af-547d-453f-d7d3-2b0df2397a8f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.02, 0.0371, 0.0428, 0.0207, 0.0954, 0.0986, 0.1539, 0.1601,\n",
              "        0.3109, 0.2111, 0.1609, 0.1582, 0.2238, 0.0645, 0.066, 0.2273,\n",
              "        0.31, 0.2999, 0.5078, 0.4797, 0.5783, 0.5071, 0.4328, 0.555,\n",
              "        0.6711, 0.6415, 0.7104, 0.808, 0.6791, 0.3857, 0.1307, 0.2604,\n",
              "        0.5121, 0.7547, 0.8537, 0.8507, 0.6692, 0.6097, 0.4943, 0.2744,\n",
              "        0.051, 0.2834, 0.2825, 0.4256, 0.2641, 0.1386, 0.1051, 0.1343,\n",
              "        0.0383, 0.0324, 0.0232, 0.0027, 0.0065, 0.0159, 0.0072, 0.0167,\n",
              "        0.018, 0.0084, 0.009, 0.0032, 'R']], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data[:, :60].astype(float)  # Assuming you want the first 60 columns as features\n",
        "Y = data[:, 60]  # Assuming column 60 is the target variable"
      ],
      "metadata": {
        "id": "7sRZsaHtTX00"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder=LabelEncoder()\n",
        "encoder.fit(Y)\n",
        "Y=encoder.transform(Y)"
      ],
      "metadata": {
        "id": "BZ4xfN2lT4N_"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler=MinMaxScaler()\n",
        "scaler.fit(X)\n",
        "X=scaler.transform(X)"
      ],
      "metadata": {
        "id": "GW0VH25UUHBl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pK7SgeEOUPZF",
        "outputId": "9b7cfc8c-c393-4391-d244-45a340c94894"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.13643068, 0.15645092, 0.13567674, 0.03542558, 0.22495562,\n",
              "        0.23757055, 0.40746753, 0.34090408, 0.4492818 , 0.28571429,\n",
              "        0.1871544 , 0.19724502, 0.29566719, 0.03836238, 0.0630956 ,\n",
              "        0.21483818, 0.28504818, 0.27262338, 0.48222175, 0.44317209,\n",
              "        0.55554384, 0.4960638 , 0.39896153, 0.54410409, 0.6630123 ,\n",
              "        0.60513272, 0.69576636, 0.80238781, 0.67441153, 0.34558432,\n",
              "        0.08991826, 0.24713548, 0.48766145, 0.77742448, 0.8503631 ,\n",
              "        0.84949597, 0.69330855, 0.59415618, 0.48197343, 0.28616558,\n",
              "        0.01737116, 0.33919414, 0.36531747, 0.54831229, 0.37546204,\n",
              "        0.19007131, 0.19032959, 0.40221623, 0.1933367 , 0.39272727,\n",
              "        0.2310757 , 0.02710414, 0.15584416, 0.43567251, 0.14965986,\n",
              "        0.41794872, 0.50284091, 0.18535469, 0.24517906, 0.06004619],\n",
              "       [0.32300885, 0.22160309, 0.27201051, 0.15002378, 0.28303322,\n",
              "        0.66675625, 0.57440476, 0.75545755, 0.48304457, 0.39453739,\n",
              "        0.65631646, 0.92555686, 0.96948323, 0.77591008, 0.7456114 ,\n",
              "        0.94463668, 1.        , 0.88301299, 0.79213129, 0.76648116,\n",
              "        0.49536256, 0.39188222, 0.35964819, 0.37649831, 0.30840164,\n",
              "        0.25101883, 0.29309801, 0.25555784, 0.43415179, 0.15074039,\n",
              "        0.36032698, 0.28566614, 0.15824845, 0.22564918, 0.11077017,\n",
              "        0.41350806, 0.38093155, 0.07008423, 0.15485979, 0.20185185,\n",
              "        0.1521714 , 0.06434676, 0.1811716 , 0.20973976, 0.08828547,\n",
              "        0.02783873, 0.09597972, 0.22222222, 0.20646138, 0.07393939,\n",
              "        0.12450199, 0.10841655, 0.21818182, 0.11111111, 0.19954649,\n",
              "        0.47948718, 0.38920455, 0.10526316, 0.14049587, 0.08775982],\n",
              "       [0.18215339, 0.24689241, 0.35611038, 0.24369948, 0.2300279 ,\n",
              "        0.58532653, 0.64880952, 0.81940463, 0.81785873, 0.86958387,\n",
              "        0.85694031, 1.        , 0.77155607, 0.52047025, 0.6468051 ,\n",
              "        0.68888663, 0.66417988, 0.74555844, 0.88733432, 0.85220462,\n",
              "        0.78646712, 0.66639403, 0.39525273, 0.349247  , 0.52161885,\n",
              "        0.16433528, 0.48208845, 0.84901194, 0.59780844, 0.84169596,\n",
              "        0.87520436, 0.52134352, 0.14543736, 0.26465289, 0.41004398,\n",
              "        0.29868952, 0.6303302 , 0.66268067, 0.52751423, 0.50130719,\n",
              "        0.49646786, 0.30903541, 0.27531359, 0.28626643, 0.30011373,\n",
              "        0.02413604, 0.24411445, 0.2228212 , 0.06562342, 0.12848485,\n",
              "        0.03286853, 0.31954351, 0.41818182, 0.24853801, 0.39455782,\n",
              "        0.61538462, 0.88920455, 0.36842105, 0.25895317, 0.16628176],\n",
              "       [0.06268437, 0.07072439, 0.19973719, 0.03495007, 0.03499873,\n",
              "        0.07148616, 0.28814935, 0.26923925, 0.07744706, 0.16459316,\n",
              "        0.08393591, 0.25732708, 0.        , 0.20501186, 0.17032802,\n",
              "        0.20038673, 0.03564397, 0.19802597, 0.3751315 , 0.35498716,\n",
              "        0.23492833, 0.35487169, 0.52908763, 0.47198033, 0.29713115,\n",
              "        0.48606675, 0.50162832, 0.23013586, 0.19744318, 0.31383829,\n",
              "        0.62975477, 0.77915075, 0.59256537, 0.3481717 , 0.38150762,\n",
              "        0.29556452, 0.55291931, 0.87667672, 1.        , 0.98583878,\n",
              "        0.6671685 , 0.6043956 , 0.4151041 , 0.41252255, 0.61060563,\n",
              "        0.50109709, 0.48080406, 0.4719976 , 0.34376577, 0.35636364,\n",
              "        0.24003984, 0.16119829, 0.08051948, 0.40935673, 0.17913832,\n",
              "        0.17692308, 0.13352273, 0.09382151, 0.10743802, 0.25635104],\n",
              "       [0.55088496, 0.28289756, 0.15308804, 0.07988588, 0.13264012,\n",
              "        0.14700349, 0.31818182, 0.53186329, 0.51665926, 0.62147862,\n",
              "        0.54771019, 0.54454865, 0.5861523 , 0.39826751, 0.45109841,\n",
              "        0.52554447, 0.72085794, 0.60446753, 0.16179255, 0.42594178,\n",
              "        0.38322091, 0.41641959, 0.5475257 , 0.52863436, 0.29928279,\n",
              "        0.15023681, 0.68431558, 1.        , 0.72219968, 0.4379461 ,\n",
              "        0.50365123, 0.56784992, 0.25244146, 0.08150503, 0.17674133,\n",
              "        0.41340726, 0.46501203, 0.29468649, 0.25901328, 0.25196078,\n",
              "        0.18749276, 0.29157509, 0.2388465 , 0.10834836, 0.0983793 ,\n",
              "        0.07240812, 0.06465049, 0.02545672, 0.11610298, 0.05575758,\n",
              "        0.15537849, 0.03281027, 0.12727273, 0.27777778, 0.23582766,\n",
              "        0.02820513, 0.19602273, 0.10297483, 0.29201102, 0.20323326]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "bvuDDiUyUXbU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model building"
      ],
      "metadata": {
        "id": "6c8ERlppUdkr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "# create a model without dropout layers\n",
        "# model = tf.keras.Sequential([\n",
        "#     tf.keras.layers.Dense(30, activation='relu', input_shape=(60,)),\n",
        "#     tf.keras.layers.Dense(60, activation='relu'),\n",
        "#     tf.keras.layers.Dense(60, activation='relu'),\n",
        "#     tf.keras.layers.Dense(30, activation='relu'),\n",
        "#     tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "# ])\n",
        "\n",
        "# create a model with droput layers\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(30, activation='relu', input_shape=(60,)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(60, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(60, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(30, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "f_2ax89uUbuc"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "             optimizer = tf.keras.optimizers.Adam(learning_rate=0.005),\n",
        "             metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "n-m05L-8UqMk"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_number = 100\n",
        "history = model.fit(X_train, y_train, epochs=epoch_number)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKA5FUV9UvaU",
        "outputId": "e01f2f60-e0ed-4b7b-e0d3-b08a6437f9d6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4721 - loss: 0.7210\n",
            "Epoch 2/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5534 - loss: 0.6900 \n",
            "Epoch 3/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5656 - loss: 0.6663 \n",
            "Epoch 4/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5757 - loss: 0.6646 \n",
            "Epoch 5/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6652 - loss: 0.6418 \n",
            "Epoch 6/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6564 - loss: 0.6253  \n",
            "Epoch 7/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7510 - loss: 0.5365 \n",
            "Epoch 8/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7312 - loss: 0.5759 \n",
            "Epoch 9/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7782 - loss: 0.4985 \n",
            "Epoch 10/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8291 - loss: 0.4532 \n",
            "Epoch 11/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8121 - loss: 0.4485\n",
            "Epoch 12/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7944 - loss: 0.4637 \n",
            "Epoch 13/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7974 - loss: 0.3785  \n",
            "Epoch 14/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8222 - loss: 0.4345 \n",
            "Epoch 15/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8167 - loss: 0.4494 \n",
            "Epoch 16/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8279 - loss: 0.3962 \n",
            "Epoch 17/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8569 - loss: 0.3358 \n",
            "Epoch 18/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8213 - loss: 0.3611 \n",
            "Epoch 19/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8450 - loss: 0.3278  \n",
            "Epoch 20/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8647 - loss: 0.2936 \n",
            "Epoch 21/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8816 - loss: 0.2836 \n",
            "Epoch 22/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8886 - loss: 0.2661 \n",
            "Epoch 23/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8617 - loss: 0.3140  \n",
            "Epoch 24/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8921 - loss: 0.2253 \n",
            "Epoch 25/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8778 - loss: 0.2708 \n",
            "Epoch 26/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8718 - loss: 0.2176 \n",
            "Epoch 27/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8901 - loss: 0.2524 \n",
            "Epoch 28/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8755 - loss: 0.2031 \n",
            "Epoch 29/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8755 - loss: 0.2391 \n",
            "Epoch 30/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9657 - loss: 0.1498 \n",
            "Epoch 31/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8867 - loss: 0.2465 \n",
            "Epoch 32/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8861 - loss: 0.2327 \n",
            "Epoch 33/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8674 - loss: 0.3386  \n",
            "Epoch 34/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8450 - loss: 0.2997 \n",
            "Epoch 35/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8370 - loss: 0.3932 \n",
            "Epoch 36/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8789 - loss: 0.2784 \n",
            "Epoch 37/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8603 - loss: 0.2710 \n",
            "Epoch 38/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9102 - loss: 0.2260 \n",
            "Epoch 39/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9426 - loss: 0.1835 \n",
            "Epoch 40/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9247 - loss: 0.1749 \n",
            "Epoch 41/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9460 - loss: 0.1679 \n",
            "Epoch 42/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9333 - loss: 0.1819 \n",
            "Epoch 43/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8916 - loss: 0.1983 \n",
            "Epoch 44/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9740 - loss: 0.0844 \n",
            "Epoch 45/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9091 - loss: 0.1952 \n",
            "Epoch 46/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9241 - loss: 0.1638 \n",
            "Epoch 47/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9426 - loss: 0.1889  \n",
            "Epoch 48/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9389 - loss: 0.1616 \n",
            "Epoch 49/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9344 - loss: 0.1307 \n",
            "Epoch 50/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9445 - loss: 0.1201\n",
            "Epoch 51/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9426 - loss: 0.1073 \n",
            "Epoch 52/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9739 - loss: 0.0688 \n",
            "Epoch 53/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9493 - loss: 0.1080  \n",
            "Epoch 54/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9586 - loss: 0.1233 \n",
            "Epoch 55/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9177 - loss: 0.2013 \n",
            "Epoch 56/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9434 - loss: 0.1136 \n",
            "Epoch 57/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9169 - loss: 0.1976 \n",
            "Epoch 58/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9683 - loss: 0.1034\n",
            "Epoch 59/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9646 - loss: 0.1205\n",
            "Epoch 60/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9351 - loss: 0.1205\n",
            "Epoch 61/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9687 - loss: 0.1049\n",
            "Epoch 62/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9519 - loss: 0.1328\n",
            "Epoch 63/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9471 - loss: 0.1244\n",
            "Epoch 64/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9452 - loss: 0.1405\n",
            "Epoch 65/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9415 - loss: 0.1369 \n",
            "Epoch 66/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9717 - loss: 0.1166\n",
            "Epoch 67/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9878 - loss: 0.0540\n",
            "Epoch 68/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9557 - loss: 0.1120\n",
            "Epoch 69/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9650 - loss: 0.0895\n",
            "Epoch 70/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9650 - loss: 0.1662\n",
            "Epoch 71/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9240 - loss: 0.1887\n",
            "Epoch 72/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9769 - loss: 0.1047\n",
            "Epoch 73/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9795 - loss: 0.0574\n",
            "Epoch 74/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9635 - loss: 0.1125\n",
            "Epoch 75/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9527 - loss: 0.0907 \n",
            "Epoch 76/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9769 - loss: 0.0681 \n",
            "Epoch 77/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9601 - loss: 0.0794\n",
            "Epoch 78/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9546 - loss: 0.1157 \n",
            "Epoch 79/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9609 - loss: 0.1081 \n",
            "Epoch 80/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9493 - loss: 0.0863 \n",
            "Epoch 81/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9564 - loss: 0.0848 \n",
            "Epoch 82/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9743 - loss: 0.1035 \n",
            "Epoch 83/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9873 - loss: 0.0508 \n",
            "Epoch 84/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9784 - loss: 0.0630 \n",
            "Epoch 85/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9579 - loss: 0.0756 \n",
            "Epoch 86/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9452 - loss: 0.1512 \n",
            "Epoch 87/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9784 - loss: 0.0858  \n",
            "Epoch 88/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9810 - loss: 0.0841 \n",
            "Epoch 89/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9374 - loss: 0.1277 \n",
            "Epoch 90/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9709 - loss: 0.1049 \n",
            "Epoch 91/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9434 - loss: 0.1153 \n",
            "Epoch 92/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9743 - loss: 0.0833 \n",
            "Epoch 93/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9434 - loss: 0.1076 \n",
            "Epoch 94/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9598 - loss: 0.1184 \n",
            "Epoch 95/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9717 - loss: 0.0533  \n",
            "Epoch 96/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9568 - loss: 0.0866  \n",
            "Epoch 97/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9899 - loss: 0.0304 \n",
            "Epoch 98/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9810 - loss: 0.0704 \n",
            "Epoch 99/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9772 - loss: 0.0677 \n",
            "Epoch 100/100\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9948 - loss: 0.0496  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeAyjmjtU3hV",
        "outputId": "f61616c6-622b-4c72-eedb-273106a23703"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8790 - loss: 0.4378 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4101419448852539, 0.8809523582458496]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ]
}